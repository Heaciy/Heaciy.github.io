[{"content":"from typing import Tuple # char: 单字符,形如\u0026#39;h\u0026#39;,\u0026#39;a\u0026#39;,\u0026#39;c\u0026#39;,\u0026#39;k\u0026#39; # word: 词,形如\u0026#34;hack\u0026#34; class TrieNode(object): \u0026#34;\u0026#34;\u0026#34; 字符节点 \u0026#34;\u0026#34;\u0026#34; def __init__(self, char: str): self.char = char # 存储的字符 self.children = [] # 该节点的子节点 self.word_finished = False # 是否是词尾 self.counter = 1 # 出现在word中的次数 def add(root, word: str): \u0026#34;\u0026#34;\u0026#34; 向字典树中添加词 \u0026#34;\u0026#34;\u0026#34; node = root # node的初始值为root节点* for char in word: # 遍历整个word found_in_child = False # 标记当前char是否在node的子结点列表中 for child in node.children: if child.char == char: # node节点的子节点中包含当前的char child.counter += 1 # 该字符在word中出现的次数加一 node = child # node向下移动一位,即为当前字符 found_in_child = True # 标记为找到 break if not found_in_child: # 当前字符不在node的子节点列表中,则新建一个节点加入到node的子节点列表中 new_node = TrieNode(char) node.children.append(new_node) node = new_node # node移至当前节点 # 当word中所有字符被遍历完后,node即为最后一个字符,将其标记为词尾 node.word_finished = True def find_profix(root, prefix: str) -\u0026gt; Tuple[bool, int]: \u0026#34;\u0026#34;\u0026#34; 检查并返回: 1. 该前缀是否出现在添加过的词中 2. 如果是,那么有多少词组包含该前缀 \u0026#34;\u0026#34;\u0026#34; node = root if not root.children: # 如果当前节点无子节点则直接返回(False,0) return False, 0 for char in prefix: # 遍历prefix中的字符 char_not_found = True # 标记当前字符是否出现在node的子节点列表中,默认为True for child in node.children: if child.char == char: # 如果当前字符包含在node的子结点中 char_not_found = False node = child # node向前移一位,即移至当前字符的位置 break if char_not_found: # 如果当前字符不在node的子结点中则直接返回(False,0) return False, 0 # 执行至此步则表示prefix的所有字符都出现在字典树中,直接返回True和最后一个字符的counter return True, node.counter def get_all_words(root: TrieNode): all_words = [] current_word = [] # 递归方式 def tmp(root: TrieNode): for node in root.children: # 遍历当前节点的所有子节点 current_word.append(node.char) # 将当前子节点加入到current_word中 if node.word_finished: # 如果当前字符为词尾 all_words.append(current_word.copy()) # 将当前词组加入到all_words中 if node.children: tmp(node) # 当前子节点有子节点, 继续递归遍历 else: current_word.pop() # 当前子节点无子节点即为词尾,出栈 return tmp(root) # 从根节点开始 return [\u0026#39;\u0026#39;.join(word) for word in all_words] if __name__ == \u0026#34;__main__\u0026#34;: # 构造根节点和字典树 root = TrieNode(\u0026#39;*\u0026#39;) add(root, \u0026#34;hackathon\u0026#34;) add(root, \u0026#34;hack\u0026#34;) # 在字典树中查找 print(find_profix(root, \u0026#34;hac\u0026#34;)) print(find_profix(root, \u0026#39;hack\u0026#39;)) print(find_profix(root, \u0026#39;hackathon\u0026#39;)) print(find_profix(root, \u0026#39;ha\u0026#39;)) print(find_profix(root, \u0026#39;hammer\u0026#39;)) # 输出结果为: # (True, 2) # (True, 2) # (True, 1) # (True, 2) # (False, 0) # [\u0026#39;hack\u0026#39;, \u0026#39;hackathon\u0026#39;] 工作原理 算法的主要步骤\n 首先要考虑的是如何将word加入到Trie中, 这也是add方法的职责所在。它的工作方式非常简单。它需要两个参数:root node(即根节点，一般使用*)和word 然后它从单词的第一个字符开始遍历, 一次一个字符 检查当前node的子节点中是否含有该字符 如果有, 则只增加该字符的counter, 以表明该字符是重复出现 如果没有, 则只用简单的将该字符添加到当前node节点的子节点列表中 对于4\u0026amp;5这两种情况, 在考虑下一个字符之前, 都是使用node的child node作为当前节点(这意味着, 当前的child node在下一个循环中将成为node节点)  这就是在Trie中添加一个单词的所有步骤。还需要做的另一件事是在整个过程完成后标记单词的结尾。这意味着Trie的每个叶节点的word_finished属性为True。\n要搜索前缀，只需执行几个简单的步骤\n find_profix函数需要两个参数, root节点和需要搜索的profix 每次从peofix中按循序取一个字符与\u0026quot;当前node\u0026quot;的子节点比较, 找出包含该字符的节点 如果找到了, 则将该子节点作为当前node进行下一轮比较 如果未找到则返回(False, 0)表明在Trie中该前缀不存在 在试图找到一个比单词本身更大的前缀时, 该算法也将返回(False, 0) 如果Trie包含该前缀则返回(True, 该前缀出现在Trie包含的word中的次数)(即在Trie包含的所有词组中有多少个词包含该前缀)   摘自: Meidum: Implementing a Trie in Python\n原作者: Shubhadeep Roychowdhury\n ","date":"2020-12-19T00:00:00Z","image":"https://heaciy.com/p/implementing-a-trie-in-python/trie_hu5ca3eeea9d4841595d42211afa052e1d_72289_120x120_fill_q75_box_smart1.jpeg","permalink":"https://heaciy.com/p/implementing-a-trie-in-python/","title":"Implementing a Trie in Python"},{"content":"import numpy import matplotlib.pyplot import scipy.special %matplotlib inline class neuralNetwork: def __init__(self, inputnodes, hiddennodes, outputnodes, learningrate): # 初始化神经网络 self.inodes = inputnodes self.hnodes = hiddennodes self.onodes = outputnodes self.lr = learningrate # 学习率 # from node i to node j in the next layer self.wih = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes)) # 权重矩阵 self.who = numpy.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes)) self.activation_function = lambda x: scipy.special.expit(x) # 应用激活函数 def train(self, inputs_list, targets_list): inputs = numpy.array(inputs_list, ndmin=2).T targets = numpy.array(targets_list, ndmin=2).T hidden_inputs = numpy.dot(self.wih, inputs) hidden_outputs = self.activation_function(hidden_inputs) final_inputs = numpy.dot(self.who, hidden_outputs) final_outputs = self.activation_function(final_inputs) output_errors = targets - final_outputs hidden_errors = numpy.dot(self.who.T, output_errors) self.who += self.lr*numpy.dot((output_errors*final_outputs*(1.0-final_outputs)), numpy.transpose(hidden_outputs)) # 调整隐藏层与输出层之间的权重 self.wih += self.lr*numpy.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)), numpy.transpose(inputs)) # 调整输入层与隐藏层之间的权重 def query(self, inputs_list): inputs = numpy.array(inputs_list, ndmin=2).T # 输入矩阵的转置矩阵 hidden_inputs = numpy.dot(self.wih, inputs) hidden_outputs = self.activation_function(hidden_inputs) final_inputs = numpy.dot(self.who, hidden_outputs) final_outputs = self.activation_function(final_inputs) return final_outputs input_nodes = 784 # 28*28，输入层节点数 hidden_nodes = 100 # 隐藏层节点数 output_nodes = 10 # 输出层节点 learning_rate = 0.2 # 学习率 # 生成一个神经网络实例 n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate) # 加载训练数据 training_data_file = open(\u0026#34;mnist_dataset/mnist_train.csv\u0026#34;, \u0026#39;r\u0026#39;) training_data_list = training_data_file.readlines() training_data_file.close() # 训练神经网络 epochs = 5 # 训练5个世代(本篇的学习率为0.2，训练数据为六万组，训练五个世代，测试数据为一万组) for e in range(epochs): for record in training_data_list: all_values = record.split(\u0026#39;,\u0026#39;) inputs = (numpy.asfarray(all_values[1:])/255.0*0.99)+0.01 targets = numpy.zeros(output_nodes) + 0.01 targets[int(all_values[0])] = 0.99 n.train(inputs,targets) # 加载测试数据(本篇使用了一万组测试数据，正确率为95.11%，结果可能不大一致，但大概都在94%~95%) test_data_file = open(\u0026#34;mnist_dataset/mnist_test.csv\u0026#34;, \u0026#39;r\u0026#39;) test_data_list = test_data_file.readlines() test_data_file.close() # 测试神经网络 scorecard = [] for record in test_data_list: all_values = record.split(\u0026#39;,\u0026#39;) correct_label = int(all_values[0]) # print(correct_label, \u0026#34;correct lable\u0026#34;) inputs = (numpy.asfarray(all_values[1:])/255.0*0.99)+0.01 outputs = n.query(inputs) label = numpy.argmax(outputs) # print(label, \u0026#34;networks\u0026#39;s answer\u0026#34;) if(label == correct_label): scorecard.append(1) else: scorecard.append(0) pass pass # print(scorecard) # 输出训练成绩 scorecard_array = numpy.asarray(scorecard) print(\u0026#34;performances = \u0026#34;, scorecard_array.sum()*1.0/scorecard_array.size) ","date":"2019-10-13T00:00:00Z","image":"https://heaciy.com/p/neural-network-with-python/neural-network_hub24483d86c658fd613211ba0613ee712_190184_120x120_fill_q75_box_smart1.jpeg","permalink":"https://heaciy.com/p/neural-network-with-python/","title":"Neural Network With Python"},{"content":"我爱一切的花朵。\n在任何一个千红万紫的花摊上，各色花朵的壮阔交杂，成了都市中最美的点缀。\n其实并不爱花圃，爱的是旷野上随着季节变化而生长的野花和那微风吹过大地的感动。\n生活在都市里的人，迫不得已在花市中捧些切花回家。对于离开泥土的鲜花，总觉对它们产生一种疼惜又抱歉的心理，可是还是要买的。这种对花的抱歉和喜悦，总也不能过分去分析它。\n我买花，不喜欢小气派。不买也罢了。如果当日要插花，喜欢一口气给它摆成一种气势，大土瓶子哗的一下把房子加添了生命。那种生活情调，可以因为花的进入，完全改观。不然，只水瓶中一朵，也有一份清幽。\n说到清幽，在所有的花朵中，如果是想区别“最爱”，我选择一切白色的花。而白色的花中，最爱野姜花以及百合──长梗的。\n许多年前，我尚在大西洋的小岛上过日子，那时，经济情况拮据，丈夫失业快一年了。我在家中种菜，屋子里插的是一人高的枯枝和芒草，那种东西，艺术品味高，并不差的。我不买花。\n有一日，丈夫和我打开邮箱，又是一封求职被拒的回信。那一阵，其实并没有山穷水尽，粗茶淡饭的日子过得没有悲伤，可是一切维持生命之外的物质享受，已不敢奢求。那是一种恐惧，眼看存款一日一日减少，心里怕得失去了安全感。这种情况只有经历过失业的人才能明白。\n我们眼看求职再一次受挫，没有说什么，去了大菜场，买些最便宜的冷冻排骨和矿泉水，就出来了。\n不知怎么一疏忽，丈夫不见了，我站在大街上等，心事重重的。一会儿，丈夫回来了，手里捧着一小把百合花，兴匆匆的递给我，说：“百合上市了。”\n那一剎间，我突然失了控制，向丈夫大叫起来：“什么时间了？什么经济能力？你有没有分寸，还去买花?!”说着我把那束花啪一下丢到地上去，转身就跑。在举步的那一剎间，其实已经后悔了。我回头，看见丈夫呆了一两秒钟，然后弯下身，把那给撒在地上的花，慢慢拾了起来。\n我往他奔回去，喊着：“荷西，对不起。”我扑上去抱他，他用手围着我的背，紧了一紧，我们对视，发觉丈夫的眼眶红了。\n回到家里，把那孤零零的三五朵百合花放在水瓶里，我好像看见了丈夫的苦心。他何尝不想买上一大缸百合，而口袋里的钱不敢挥霍。毕竟，就算是一小束吧，也是他的爱情。\n那一次，是我的浅浮和急躁，伤害了他。以后我们没有再提这件事。\n四年以后，我去上丈夫的坟，进了花店，我跟卖花的姑娘说：“这五桶满满的花，我全买下，不要担心价钱。”\n坐在满布鲜花的坟上，我盯住那一大片颜色和黄土，眼睛干干的。以后，凡是百合花上市的季节，我总是站在花摊前发呆。\n一个清晨，我去了花市，买下了数百朵百合，把那间房子，摆满了它们。在那清幽的夜晚，我打开全家的窗门，坐在黑暗中，静静的让微风，吹动那百合的气息。\n那是丈夫逝去了七年之后。又是百合花的季节了，看见它们，立即看见当年丈夫弯腰去地上拾花的景象。没有泪，而我的胃，开始抽痛起来。\n 作者: 三毛 (选自《思念的长河》)\n ","date":"2019-09-19T00:00:00Z","image":"https://heaciy.com/p/%E5%A4%9C%E6%B7%B1%E8%8A%B1%E7%9D%A1/the-creative-exchange-d2zvqp3fpro-unsplash_huf941de4769045cdfa8c9ee7036519a2a_35369_120x120_fill_q75_box_smart1.jpg","permalink":"https://heaciy.com/p/%E5%A4%9C%E6%B7%B1%E8%8A%B1%E7%9D%A1/","title":"夜深花睡"}]